<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <title>Diploma in Apple Development ğŸğŸ‘©ğŸ»â€ğŸ’»: 2024/2025: Coding Two: Lecture 7: Tracking objects</title>
  <!-- This whole presentation was made with Big: https://github.com/tmcw/big -->

  <link href="../big/big.css" rel="stylesheet" type="text/css" />
  <script>
    BIG_ASPECT_RATIO = false;
  </script>

  <script src="../big/big.js"></script>
  <link href="../big/themes/lightWhite.css" rel="stylesheet" type="text/css" />

  <!-- Favicon link below, via https://emojitofavicon.com -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ––ğŸ»</text></svg>">

  <style>
    body {
      background-color: #EDD1B0;
    }
  </style>
</head>

<body>
  <div>Diploma in Apple Development ğŸğŸ‘©ğŸ»â€ğŸ’»: Coding Two: Lecture 7: Tracking objects.<br /><a href="../index.html">Back to slide index</a>.</div>
  <div>
    ğŸ‘‹ğŸ» Hi!
  </div>
  <div>First, don't forget to confirm your attendance using the Seats Mobile app!</div>
  <div>Second, I'm going to start every lecture with a meditation from the fantastic <a href="https://www.shambhala.com/sittingstilllikeafrog/">Sitting Still Like a Frog book</a>, all read by Myla Kabat-Zinn. If you don't want to participate that's completely fine.</div>
  <div>Let's start by watching this video from WWDC24: <a href="https://developer.apple.com/videos/play/wwdc2024/10101/">"Explore object tracking for visionOS"</a>. The source code for the app mentioned in the presentation <a href="https://developer.apple.com/documentation/visionOS/exploring_object_tracking_with_arkit">is here</a>, but let's save that for later.</div>
  <div>First, let's take a look at <a href="https://developer.apple.com/documentation/visionOS/implementing-object-tracking-in-your-visionOS-app">this article from Apple: "Implementing object tracking in your visionOS app"</a>. TLDR: we need a USDZ file of the object we want to track. <a href="https://poly.cam">I have a poly.cam account, so lets use that to make three different scans</a>. I'll AirDrop the files to one of three groups:
    <ol>
      <li><a href="https://developer.apple.com/documentation/visionos/using-a-reference-object-with-reality-composer-pro">This group is going to use this article to use Reality Composer Pro to make an app</a>.</li>
      <li><a href="https://developer.apple.com/documentation/visionos/using-a-reference-object-with-realitykit">This group is going to use this article to use RealityKit to make an app</a>.</li>
      <li><a href="https://developer.apple.com/documentation/visionos/using-a-reference-object-with-arkit">This group is going to use this article to use ARKit to make an app</a>.</li>
    </ol>
    What's the maximum number of objects you can track at once? Remember you can use GitHub code search and Claude for help!
  </div>
  <div>
    Finally, let's look through<a href="https://developer.apple.com/documentation/visionOS/exploring_object_tracking_with_arkit">the source code of the presentation</a> we saw at the beginning.
  </div>
  <div>
    Thanks! As always, please review all today's content as homework.<br /><a href="../index.html">Back to slide index</a>.
  </div>
</body>

</html>
