<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <title>Diploma in Apple Development ğŸğŸ‘©ğŸ»â€ğŸ’»: 2024/2025: Coding Two: Lecture 6: Tracking images.</title>
  <!-- This whole presentation was made with Big: https://github.com/tmcw/big -->

  <link href="../big/big.css" rel="stylesheet" type="text/css" />
  <script>
    BIG_ASPECT_RATIO = false;
  </script>

  <script src="../big/big.js"></script>
  <link href="../big/themes/lightWhite.css" rel="stylesheet" type="text/css" />

  <!-- Favicon link below, via https://emojitofavicon.com -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ğŸ––ğŸ»</text></svg>">

  <style>
    body {
      background-color: #EDD1B0;
    }
  </style>
</head>

<body>
  <div>Diploma in Apple Development ğŸğŸ‘©ğŸ»â€ğŸ’»: Coding Two: Lecture 6: Tracking images.<br /><a href="../index.html">Back to slide index</a>.</div>
  <div>
    ğŸ‘‹ğŸ» Hi!
  </div>
  <div>First, don't forget to confirm your attendance using the Seats Mobile app!</div>
  <div>Second, I'm going to start every lecture with a meditation from the fantastic <a href="https://www.shambhala.com/sittingstilllikeafrog/">Sitting Still Like a Frog book</a>, all read by Myla Kabat-Zinn. If you don't want to participate that's completely fine.</div>
  <div>Before we start the lecture proper, I'd like to demonstrate the different debugging views that Xcode offers when you run a VisionOS app in either the simulator or on a headset. For reference <a href="https://www.createwithswift.com/debug-visionos-using-xcode-simulator-visualizations/">CreateWithSwift.com has a good article about the different modes</a> - let's go through it and then try on the simulator and on a live headset.</div>
  <div>This session is going to be all about how we can track known images in visionOS. Luckily, <a href="https://developer.apple.com/documentation/visionos/tracking-images-in-3d-space">Apple has provided an article about how to do this</a> .Unfortunately, they haven't provided a complete project to work from. What should we do? Shall we try making a new project with it? Or...</div>
  <div>
    <a href="https://github.com/search?q=ImageTrackingProvider+language%3ASwift&type=code&l=Swift">GitHub code search to the rescue!</a> Notice how I've specified "ImageTrackingProvider" as the search term and specified that I want only results write in Swift. Which projects look best? Let's split into three groups, one Vision Pro each and each choose a different project to get running. Once they are all running, let's demo them to each other, before taking a dive into their code. Stop press! <a href="https://github.com/tokufxug/VisionOSImageTrackingSample">ImageTrackingSample located! Let's try it.</a>
  </div>
  <div>As a bonus, let's try prompting <a href="https://claude.ai/new">Claude</a> to build this app for us.</div>
  <div>Flynn and Rosa have already been working on Image Anchors for their final projects - how are those going? Could we have a look at your code after a demo? As a final challenge, let's look at how to detect collisions between two Image Anchors, combining Flynn and Rosa's code with some example code that I've prepared ahead of time. Let's take a look at my example code.</div>
  <div>
    Thanks! As always, please review all today's content as homework.<br /><a href="../index.html">Back to slide index</a>.
  </div>
</body>

</html>
